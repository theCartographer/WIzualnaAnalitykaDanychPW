{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt końcowy - przykładowa struktura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowy projekt z popularnymi danymi iris species:\n",
    "    \n",
    "https://github.com/Bhard27/Iris-Species-Classification/blob/master/data/iris_classification.ipynb\n",
    "\n",
    "Warte przeczytania:\n",
    "\n",
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "\n",
    "https://towardsdatascience.com/the-art-of-cleaning-your-data-b713dbd49726#:~:text=In%20the%20context%20of%20data%20scien%20c%20e,don%E2%80%99t%20need%20to%20look%20at%20or%20process%20them\n",
    "\n",
    "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "\n",
    "https://machinelearningmastery.com/combine-oversampling-and-undersampling-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 1 - obróbka danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj podobnie jak w części 2 i 3 trudno jasno wskazać notebooki i zajęcia, bo praktycznie każde zajęcia w części Machine Learning zawierały coś w tej praktycznej cześci, czyli omawiania zawartości notebooków coś z obróbki danych.\n",
    "\n",
    "Tutaj artykuł, który ułatwi Wam pracę: \n",
    "https://towardsdatascience.com/the-art-of-cleaning-your-data-b713dbd49726#:~:text=In%20the%20context%20of%20data%20scien%20c%20e,don%E2%80%99t%20need%20to%20look%20at%20or%20process%20them.\n",
    "\n",
    "Jeśli nie będziecie mieli dostępu do artykułów z towardsdatascience, to otwierajcie je w trybie prywatnym tzn. np w google chrome klikacie trzy kropki i wybieracie \"nowe okno incognito\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Poprawne wczytanie danych z pliku\n",
    "\n",
    "2. Usunięcie kolumn które zawierają informacje z przyszłości, niedostępne w momencie udzielania pożyczki\n",
    "\n",
    "3. Usunięcie kolumn ze zbędnymi informacjami\n",
    "\n",
    "4. Usunięcie kolumn tylko jedną unikalną wartością\n",
    "\n",
    "5. Rzut okiem na wartości w kolumnie ze statusem pożyczki\n",
    "\n",
    "6. Przekształcenie wartości w kolumnach - usunięcie procentów, dodatkowych znaków, itd\n",
    "\n",
    "7. Analiza brakujących wartości wraz z ich uzupełnieniem/usunięciem przy wzięciu pod uwagę pewnych ustalonych kryteriów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2 - eksploracyjna analiza danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowy notebook z zawartą eksploracyjną analiza danych: Feature+eng,+model+selection+&+tuning.ipynb\n",
    "    \n",
    "Zajęcia, które mogą przydać się do wizualizacji: Wizualizacje (część Python)\n",
    "    \n",
    "Nie mniej jednak eksploracyjną analize danych robiliśmy w mniejszej lub większej ilości w każdym z notebooków dot. modelowania. Pamiętajcie, że macie problem klasyfikacyjny, więc nie będzie trzeba eksplorować danych pod kątem spełnienia założeń, które powinny być spełnione przy użyciu np. regresji liniowej. Do wizualizacji może się też przydać notebook pod zajęciami z wizualizacji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wysokopoziomowa analiza cech - ogólny rzut okiem który pozwoli lepiej zrozumieć dane\n",
    "\n",
    "2. Sprawdzenie korelacji zmiennych (z targetem/między sobą) - choć korelacja bada liniową zależność, a ta może przybierać wiele form to wygenerowanie mapki korelacji może podsunąć kolumny którym warto się przyglądnąć\n",
    "\n",
    "3. Odpowiedź na 6 pytań z treści projektu:\n",
    "    * dobrze dobrana wizualizacja\n",
    "    * opisanie własnych obserwacji\n",
    "    * poparcie testem statystycznym (opcjonalnie)\n",
    "    \n",
    "4. Dalsza, autorska eksploracja - rozbudowanie części projektu o Wasze pomysły, hipotezy i odkryte wcześniej rzeczy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 3 - feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj najwięcej dowiecie się co zawiera sie pod pojęciem feature engineering właśnie w tym artykule wspomnianym poniżej: https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "\n",
    "\n",
    "W każdym notebooku mieliśmy zawartą jakąś część dot. feature engineeringu, więc ciężko tutaj podac Wam konkretne przykłady a rzeczy z punktu 2 będziecie musieli robić na podstawie wiedzy domenowej i nie da się tego znaleźć w żadnym z notebook'ów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dużą część operacji zaliczających się do feature engineeringu znajdziecie tutaj: https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "2. Poza tym, można pokusić się o własne, \"eksperckie\" cechy - na przykład\n",
    "  * dodanie kolumny z propozycją wskaźnika finansowego - na przykład stosunek otrzymanej kwoty pożyczki do wnioskowanej\n",
    "  * dodanie kolumny z informacją czy pożyczka jest konsolidacyjna bądź nie (1 - tak, 0 - nie, a samą informajcę \"wydłubać z jednej z dostępnych kolumn)\n",
    "  * dodanie kolumny z informacją czy pożyczkobiorca bogato opisał cel pożyczki (może ci co opisuja rozwlekle to lepiej spłacają? albo są pewne słowa klucze których pojawienie się w opisie zmniejsza/zwiększa szansę na spłatę?)\n",
    "  * i wiele innych, które przyjdą Wam do głowy\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 4 - modelowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Wykorzystanie trzech algorytmów klasteryzacji - można dowolne, proponuję KMeans, Hierarchiczną i DBScan, jak na zajęciach.\n",
    "\n",
    "<b> Zajęcia </b>: Uczenie nienadzorowane\n",
    "\n",
    "<b> Notebook </b>: Uczenie+nienadzorowane.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Uzasadnienie doboru określonej liczby klastrów - dla powyższych metod do dyspozycji mamy metodę łokcia, wskaźnik sylwetkowy i dendrogram\n",
    "\n",
    "<b> Zajęcia </b>: Uczenie nienadzorowane\n",
    "\n",
    "<b> Notebook </b>: Uczenie+nienadzorowane.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sprawdzenie dla otrzymanych klastrów:\n",
    "  * czy są zbalansowane\n",
    "  * czym różnią się pożyczkobiorcy w poszczególnych klastrach\n",
    "  * czy spłacalność w klastrach się różni (najbardziej istotne biznesowo pytanie, jeśli są takie przesłanki to można numer klastra dołączyć nawet jako dodatkową kolumnę i wykorzystać w modelowaniu)\n",
    "  \n",
    "  \n",
    "<b> Zajęcia </b>: Uczenie nienadzorowane\n",
    "\n",
    "<b> Notebook </b>: Uczenie+nienadzorowane.ipynb  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Wytrenowanie 5 różnych modeli - 5 klasyfikatorów, fajnie jakby fundamentalnie się różniły, tzn część bazowała na odległościach (np. regresja logistyczna), a część na decyzjach (np. drzewo decyzyjne/las losowy)\n",
    "\n",
    "<b> Zajęcia </b>: Wszystkie z modelami oprócz CNN, RNN oraz uczenia nienadzorowanego i bez modeli dla problemów regresyjnych. tzn. np bez pierwszych zajęć o regresji liniowej\n",
    "\n",
    "<b> Notebook </b>: \n",
    "np. metody bazujące na drzewach decyzyjnych: Ensemble+Learning.ipynb, \n",
    "regresja logistyczna: Lekcja+2+-+Regresja+logistyczna.ipynb. \n",
    "Wiele metod znajdziecie w Feature+eng,+model+selection+&+tuning.ipynb, ale <b>UWAGA!</b> Wy macie problem klasyfikacyjny, więc np. zamiast użycia RandomForestRegressor będziecie użuwać RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Skompresowanie danych metodą PCA (albo tak żeby zachować xx% zmienności, albo do wybranej liczby komponentów - np. redukcja liczby kolumn ze 100 do 20)\n",
    "\n",
    "<b> Zajęcia </b>: Uczenie nienadzorowane (część poświęcona PCA)\n",
    "\n",
    "<b> Notebook </b>: Uczenie+nienadzorowane.ipynb  (część poświęcona PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Wytrenowanie tych samych modeli co wcześniej, ale na danych skompresowanych i porównanie otrzymanych wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Wybranie jednego, finalnego modelu oraz dokładna jego analiza:\n",
    "  * Dopasowanie parametrów modelu\n",
    "  * Walidacja krzyżowa\n",
    "  * Wygenerowanie krzywej ROC, obliczenie AUROC score i być może innych, dodatkowych metryk\n",
    "  * Sprawdzenie bias-variance tradeoff - czyli czy model jest zbyt słabo a może nadmiernie dopasowany? Pomocny może być kod z zajęć do generowania \"learning_curves\"\n",
    "  * Sprawdzenie istotnych cech - to znaczy na podstawie jakich cech model podejmuje decyzję i czy waszym zdaniem ma to sens\n",
    "  * Jeśli klasy są niezbalansowane w targecie, można pokusić się o ich zbalansowanie i sprawdzenie wyniku na zbalasnowanych (link do metody: https://machinelearningmastery.com/combine-oversampling-and-undersampling-for-imbalanced-classification/)\n",
    "  \n",
    "<b> Zajęcia </b>: Metryki ewaluacyjne znajdziecie w zajęciach o regresji logistycznej, czyli logit. Sprawdzenie bias variance trade off i inne głównie w Bias & Variance, Reg, Model selection \n",
    "\n",
    "<b> Notebook </b>: Głównie Feature+eng,+model+selection+&+tuning.ipynb, ale metryki i inne rzeczy z podpunktu są też w innych notebookach np. learning_curves w notebooku Learning+Curves+-+Bias-variance+tradeoff.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
